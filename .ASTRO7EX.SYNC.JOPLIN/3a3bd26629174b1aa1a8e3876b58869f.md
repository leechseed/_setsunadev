README — Full System: SlimeVR Body Tracking + ARKit Facial Capture

# README — Full System: SlimeVR Body Tracking + ARKit Facial Capture

> Straight to the point: this system uses **SlimeVR-style IMU trackers** for full-body **rotations** and **ARKit** (iPhone with TrueDepth) for **facial blendshapes**. No base stations. No optical tracking. Expect excellent expressiveness and portable setup, with the usual IMU caveats (yaw drift over long takes, no absolute position).

---

## Table of Contents

* [1. System Overview](#1-system-overview)
* [2. What Each Part Does (Ownership)](#2-what-each-part-does-ownership)
* [3. Hardware](#3-hardware)

  * [3.1 Tracker BOM (per node)](#31-tracker-bom-per-node)
  * [3.2 Recommended Node Count & Placement](#32-recommended-node-count--placement)
  * [3.3 Enclosures & Mounting](#33-enclosures--mounting)
  * [3.4 Power & Charging](#34-power--charging)
* [4. Firmware & On-Node Settings](#4-firmware--on-node-settings)
* [5. Networking & Transport](#5-networking--transport)
* [6. Host Software Stack](#6-host-software-stack)

  * [6.1 SlimeVR Server](#61-slimevr-server)
  * [6.2 Facial Capture (ARKit)](#62-facial-capture-arkit)
  * [6.3 Engine Integration (pick one)](#63-engine-integration-pick-one)
* [7. Time Sync & Latency Strategy](#7-time-sync--latency-strategy)
* [8. Calibration & Session Workflow](#8-calibration--session-workflow)
* [9. Data Formats & Rates](#9-data-formats--rates)
* [10. Rig & Retargeting](#10-rig--retargeting)
* [11. Quality Tips (What Actually Matters)](#11-quality-tips-what-actually-matters)
* [12. Troubleshooting](#12-troubleshooting)
* [13. Maintenance & Safety](#13-maintenance--safety)
* [14. Extensions & Variants](#14-extensions--variants)
* [15. Quick Checklists](#15-quick-checklists)

---

## 1. System Overview

```mermaid
flowchart LR
  subgraph Wearer
    A1[IMU Nodes xN\n(ESP32-S3 + BNO085)]
    A2[iPhone (TrueDepth)\nARKit Face App]
  end

  A1 -- UDP (Wi-Fi) --> B1[SlimeVR Server\n(on PC)]
  A2 -- Wi-Fi --> C1[Face Receiver\n(Engine plugin/app/OSC)]

  B1 -- body quats --> D[Engine (Unreal/Unity/Blender)]
  C1 -- blendshapes --> D
  D --> E[Character Rig\n(Retarget + Facial Rig)]
```

* **Body**: SlimeVR trackers stream **quaternions** (rotations only) to SlimeVR Server → engine.
* **Face**: iPhone streams **ARKit blendshapes** (+ optional head pose) to engine.
* **No absolute position**: all body motion is solved via IK. Root/feet won’t have real world coordinates—accept it or add anchors later (not in this build).

---

## 2. What Each Part Does (Ownership)

| Component         | Owns                                                          | Why                                                   |
| ----------------- | ------------------------------------------------------------- | ----------------------------------------------------- |
| **SlimeVR nodes** | Body **bone rotations** (hips, spine, head, arms, legs, feet) | High-rate IMU quats are smooth; IK handles positions. |
| **ARKit**         | **Facial blendshapes** (and optionally eye/gaze)              | Best-in-class face fidelity on consumer gear.         |
| **Engine**        | **Skeleton solve & retarget**                                 | One rig, one place to blend face/body and export.     |

**Head orientation rule:** Use the **head IMU** for head rotation. Apply ARKit face **as local offsets** on the head/face rig. Don’t let ARKit head pose and IMU fight.

---

## 3. Hardware

### 3.1 Tracker BOM (per node)

* **IMU:** BNO085/BNO080 (Hillcrest SH-2 fusion).
* **MCU/Radio:** ESP32-S3 dev board (USB-C; onboard LiPo charger preferred).
* **Battery:** LiPo 3.7 V, **750–1000 mAh** (≈6–10 h).
* **Switch & wiring:** Mini slide switch, JST-PH leads, short SPI (or short I²C) harness.
* **Case & strap:** 3D-printed PETG/ABS case; elastic/Velcro strap; M2 standoffs.

**Cost per node:** ~$45–70 (realistic).

### 3.2 Recommended Node Count & Placement

Ten-node layout (rock-solid body solve without overkill):

1. Hips/Pelvis (belt line, center)
2. Lower Spine (navel)
3. Upper Chest (sternum)
4. Head (headband/cap)
   5–6. Upper Arms L/R (lateral deltoid)
   7–8. Forearms L/R (dorsal mid-forearm)
   9–10. Feet L/R (instep/laces)

> Feet, not shins: better foot-plant detection and less skate with IMU-only rigs.

### 3.3 Enclosures & Mounting

* **Rigid** mount (no wobble).
* **Orientation marks** on case (“UP”, “FWD”).
* Keep IMU away from **magnets** (headphones, buck inductors).
* Straps tight but not cutting off circulation. Soft pads if needed.

### 3.4 Power & Charging

* Draw: ~80–120 mA per node @ 100–200 Hz Wi-Fi.
* Runtime: **750–1000 mAh → 6–10 h**.
* Bench: multi-port USB-C charger for the fleet.
* Swap LiPos yearly under heavy use (300–500 cycles).

---

## 4. Firmware & On-Node Settings

* **Fusion:** BNO085 **Game Rotation Vector** (gyro+accel; **mag off** indoors).
* **Internal update:** 400 Hz; **publish 100–200 Hz**.
* **Packet:** timestamp (µs) + quaternion (Q15 fixed-point) + id + flags (~20–24 B).
* **Transport:** **Wi-Fi UDP** (SlimeVR default).
* **Per-node ID:** hardcode names matching mount (HIPS, CHEST, …).
* **Warm-up:** 60–120 s before recording.
* **Stillness rebias:** enabled; let nodes recalibrate when actor stands idle.

---

## 5. Networking & Transport

* Dedicated **5 GHz** SSID for trackers + iPhone; **PC on Ethernet** to the same router.
* Disable power-save on ESP32; keep nodes in same room as AP.
* Packet loss? Drop to 100 Hz; keep packets tiny; kill background cloud crap on the PC.

---

## 6. Host Software Stack

### 6.1 SlimeVR Server

* Runs on the PC. Receives node quats over UDP, does body solve, exposes outputs to your engine (OpenVR/OSC/VRChat bridges exist; for Unreal/Unity use the plugin/connector you prefer).
* Use the server’s **Mounting/Alignment** tool after you strap in.

### 6.2 Facial Capture (ARKit)

* **Device:** iPhone with TrueDepth (FaceID).
* **App:** any ARKit face app that streams blendshapes (e.g., Live Link Face for Unreal; for Unity/Blender use an OSC/UDP sender app or a bridge).
* **Configuration:**

  * Ensure **same LAN** as the PC.
  * **Disable ARKit head pose** in the engine if it conflicts—remember the head IMU owns head rotation.
  * Map ARKit blendshape names → your facial rig (one-time setup).

### 6.3 Engine Integration (pick one)

**Unreal (recommended for live)**

* Inputs: SlimeVR (via OpenVR/OSC/Live Link bridge) + ARKit (Live Link Face).
* Use **Control Rig** to apply IMU rotations to bones; facial blendshapes through Live Link.
* Export via Take Recorder or bake to Control Rig → FBX.

**Unity**

* Inputs: SlimeVR (OSC/OpenVR bridge) + ARKit (OSC/UDP).
* Apply quats with **FinalIK**/custom scripts; drive blendshapes via mapping component.
* Record with Timeline/Recorder.

**Blender (best offline)**

* Import SlimeVR quats (CSV/OSC capture) → drivers/constraints.
* Import ARKit curves → shape keys.
* Clean, then export FBX.

---

## 7. Time Sync & Latency Strategy

* IMU stream ≈ **20–40 ms** pipeline; ARKit ≈ **40–70 ms**.
* For live preview, **buffer faster stream to the slower** (usually ARKit).
* If you don’t want to build fancy sync: **accept 1–2 frames of mis-alignment**. For offline, record raw and align in post.

---

## 8. Calibration & Session Workflow

**Before first use (per node):**

1. Power on, warm up 1–2 min.
2. Stationary bias (don’t touch). Save to NVS.

**Each session:**

1. Charge everything. Mount nodes consistently (follow the arrows).
2. Launch SlimeVR Server; connect nodes.
3. **T-pose alignment** in server; verify axes (elbows bend the right way).
4. Start ARKit face app; confirm blendshapes arrive; disable head pose if needed.
5. Do a **walk/arm-swing test**; let stillness rebias fire after 10–20 s of standing.
6. Record: capture **raw** (optional) + final (engine).
7. Between takes: keep stillness rebias on; long breaks → power-cycle nodes.

---

## 9. Data Formats & Rates

**Tracker packet (suggested; SlimeVR uses its own but conceptually this):**

```c
struct PosePkt {
  uint32_t t_us;            // monotonic timestamp (microseconds)
  int16_t qx, qy, qz, qw;   // quaternion (Q15)
  uint8_t id;               // tracker ID
  uint8_t flags;            // calib_ok, fifo_overrun, etc.
}; // ~20–22 bytes
```

* **Rate:** 100–200 Hz per node.
* **Total throughput:** trivial on 5 GHz (dozens of kB/s).

---

## 10. Rig & Retargeting

* **One skeleton**. Don’t mix bone names/axes across tools.
* **Scale** once; keep consistent.
* **Head ownership**: IMU drives head rotation; ARKit drives shapes.
* **Feet**: with IMU-only rigs, some skate is inevitable; use IK foot pins/constraints in engine to help.

---

## 11. Quality Tips (What Actually Matters)

* **Rigid mounts** > everything. Wobble = garbage data.
* **Mag off** indoors. Yaw drift? Use stillness rebias; keep takes sane length.
* **Dedicated Wi-Fi**. PC wired. No walls/metal racks between AP and actor.
* **Warm-up** before alignment.
* **Consistent don/doff**: same strap spots, same arrow directions, every time.

---

## 12. Troubleshooting

| Symptom            | Cause                         | Fix                                                                             |
| ------------------ | ----------------------------- | ------------------------------------------------------------------------------- |
| Slow turning drift | Gyro bias, mag disabled       | Let stillness rebias trigger; keep takes shorter; power-cycle if it gets silly. |
| Arms bend wrong    | Mount orientation mismatch    | Re-run mounting tool; fix case arrows; remap axes in server.                    |
| Stutter / lag      | Wi-Fi congestion / power-save | Dedicated 5 GHz, disable ESP power-save, drop to 100 Hz, wire PC.               |
| Feet slide         | IMU-only limitation           | Use stronger IK foot pins; prefer **foot** nodes (not shins).                   |
| Head “fights” face | Double-driving                | IMU owns head rotation; apply ARKit shapes as local offsets only.               |
| One tracker noisy  | Loose strap / EMI             | Tighten, move away from magnets, check wiring, swap LiPo if sagging.            |

---

## 13. Maintenance & Safety

* Inspect straps, cases, and JST leads weekly.
* Store LiPos at ~50% if shelving for weeks.
* Keep batteries insulated from PCB edges; don’t crush/crease pouches.
* Replace swollen or weak packs. Common sense.

---

## 14. Extensions & Variants

* **More nodes (12)**: add upper legs or shins if you prefer; minor gain vs complexity.
* **Hands/fingers**: separate system (Leap, gloves).
* **Absolute position**: add a single anchor (UWB, lighthouse hip puck) later. Not covered here.

---

## 15. Quick Checklists

**Build (per node)**

* [ ] ESP32-S3 + BNO085 wired (SPI preferred), short leads
* [ ] Case printed, arrows marked, strap fitted
* [ ] LiPo + switch + charge verified
* [ ] Firmware flashed, unique ID set
* [ ] Warm-up + bias saved

**Session**

* [ ] All nodes charged & mounted (same spots)
* [ ] SlimeVR Server running; nodes green
* [ ] T-pose alignment passed (axes correct)
* [ ] ARKit face connected; head pose disabled if needed
* [ ] Quick walk test; stillness rebias confirmed
* [ ] Record raw (optional) + final

---

### Final word

This setup is **portable, cheap, and expressive**. You won’t get absolute world positions; you **will** get clean rotations and a great face. Keep mounts rigid, Wi-Fi clean, and sessions sane. If later you need drift-free root/feet, we can bolt on one anchor system—but you don’t need it to ship solid results with this rig.


id: 3a3bd26629174b1aa1a8e3876b58869f
parent_id: 7281cae0eaec48078ff2080548ab7931
created_time: 2025-09-28T18:21:59.259Z
updated_time: 2025-09-28T18:22:01.079Z
is_conflict: 0
latitude: 30.43825590
longitude: -84.28073290
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 0
user_created_time: 2025-09-28T18:21:59.259Z
user_updated_time: 2025-09-28T18:22:01.079Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
deleted_time: 0
type_: 1