id: 899136a968e241e996d950143940303b
parent_id: 3d122c49d2d64558beca26efb945113f
item_type: 1
item_id: 65869cfb26514c06b2b62a463b14bd96
item_updated_time: 1759836283485
title_diff: "[]"
body_diff: "[{\"diffs\":[[0,\"ements.\\\n\"],[1,\"\\\n# B. Accessibility, Simplicity, and Data Quality in the Motion Capture Process\\\n- The quality of motion capture data is a central point that\\\nunderlies the creation of 3D animations that appear realistic\\\nand natural. To achieve optimal data quality, a high level\\\nof accuracy is required in recording every movement. This\\\ninvolves efforts to reduce noise that can blur details and\\\naddress potential issues such as the emergence of double\\\nsilhouettes, which can diminish the authenticity of the\\\nrecorded movements. In this context, achieving good data\\\nquality is not merely a matter of accuracy but also involves\\\nfinding a balance between accuracy and data acquisition\\\nspeed. Technology that can present a harmony between\\\nhigh accuracy and efficiency in the data acquisition process\\\nplays a crucial role in producing impressive 3D animations.\\\n- An effective motion capture system is not only capable\\\nof recording movements with high precision but also can\\\ndo so without sacrificing the speed of data acquisition.\\\n- Thus, such technology not only supports the creation of\\\nmore realistic animations but also ensures that the animation\\\nproduction workflow can proceed efficiently and effectively.\\\n- To meet market expectations for increasingly realistic 3D\\\nanimations, attention to motion capture data quality as a\\\nkey element becomes increasingly important. Therefore,\\\nthe continuous development of motion capture technology\\\nimproving data quality, minimizing noise, and addressing\\\nissues such as double silhouettes become a fundamental\\\nfoundation to propel the animation industry to higher levels.\\\n\\\n# C. Discussion\\\n- The spotlight on the\\\nrole of machine learning algorithms suggests that motion\\\ncapture technology can be further enhanced with artificial\\\nintelligence integration. Machine learning algorithms can\\\nhelp improve accuracy and data processing, unlocking new\\\npotentials for the development of this technology.\\\nThe\\\nemphasis on Balance, as recognized in this research, under-\\\nscores that achieving success in motion capture use requires\\\nalignment between accessibility, data quality, and real-\\\ntime efficiency. This necessitates careful attention to each\\\nof these key elements during the implementation process.\\\nFinally, the potential and challenges in the development of\\\nmotion capture technology highlight that while this technol-\\\nogy has great potential in creating realistic 3D animations,\\\nchallenges such as costs, resource needs, and integration\\\nwith animation software remain a focus of concern.\\\n\\\n# E. Considerations for Future research\\\n- Furthermore, future research can\\\ndelve into the development of machine learning algorithms\\\nspecifically designed to enhance the accuracy and efficiency\\\nof motion capture data processing. The presence of more\\\nadvanced algorithms can bring significant improvements to\\\nmotion capture technology, creating a stronger foundation\\\nfor the development of more sophisticated applications.\\\n\\\n\\\n### **Research Sources**\\\n\\\n1. [32]  C. Lu, Z. Dai, and L. Jing, “Measurement of hand joint angle\\\nusing inertial-based motion capture system,” IEEE Transactions on\\\nInstrumentation and Measurement, vol. 72, 2023.\\\n2. [39]  R. Colella, S. Sabina, P. Mincarone, and L. Catarinucci, “Semi-\\\npassive rfid electronic devices with on-chip sensor fusion capabili-\\\nties for motion capture and biomechanical analysis,” IEEE Sensors\\\nJournal, vol. 23, no. 11, pp. 11 672–11 681, 2023.\\\n3. [40]  D. Jiang, J. W. Li, X. Geng, X. Ma, and W. M. Chen, “Fast tool to\\\nevaluate 3d movements of the foot-ankle complex using multi-view\\\ndepth sensors,” Medicine in Novel Technology and Devices, vol. 17,\\\np. 100212, 2023.\\\n4. [42]  N. M. Philipp, D. Cabarkapa, D. V. Cabarkapa, D. A. Eserhaut, and\\\nA. C. Fry, “Inter-device reliability of a three-dimensional markerless\\\nmotion capture system quantifying elementary movement patterns\\\nin humans,” Journal of Functional Morphology and Kinesiology,\\\nvol. 8, no. 2, p. 69, 2023.\\\n5. [44]  M. Younesi Heravi, Y. Jang, I. Jeong, and S. Sarkar, “Deep learning-\\\nbased activity-aware 3d human motion trajectory prediction in con-\\\nstruction,” Expert Systems with Applications, vol. 239, p. 122423,\\\n2024.\\\n6. [45]  Q. Gao, Z. Deng, Z. Ju, and T. Zhang, “Dual-hand motion capture by\\\nusing biological inspiration for bionic bimanual robot teleoperation,”\\\nCyborg and Bionic Systems, vol. 4, 2023.\\\n7. [46]  C. Gonc¸alves, J. M. Lopes, S. Moccia, D. Berardini, L. Migliorelli,\\\nand C. P. Santos, “Deep learning-based approaches for human\\\nmotion decoding in smart walkers for rehabilitation,” Expert Systems\\\nwith Applications, vol. 228, p. 120288, 2023.\\\n8. [47]  C. Gu, J. Yu, and C. Zhang, “Learning disentangled representations\\\nfor controllable human motion prediction,” Pattern Recognition, vol.\\\n146, p. 109998, 2024.\\\n9. [48]  Y. Huang, “Whole-body motion capture and beyond: From model-\\\nbased inference to learning-based regression,” 2022. [Online]. Avail-\\\nable: https://doi.org/http://dx.doi.org/10.15496/publikation-75583\\\n10. [49]  D. H. Hwang, K. Aso, Y. Yuan, K. Kitani, and H. Koike, “Monoeye:\\\nMultimodal human motion capture system using a single ultra-wide\\\nfisheye camera,” in UIST 2020 - Proceedings of the 33rd Annual\\\nACM Symposium on User Interface Software and Technology.\\\nACM, 2020, pp. 98–111.\\\n11. [50]  J. E. Manzi, B. Dowling, S. Krichevsky, N. L. S. Roberts, S. Y. Sudah, J. Moran, F. R. Chen, T. Quan, K. W. Morse, and J. S. Dines,\\\n“Pitch-classifier model for professional pitchers utilizing 3d motion\\\ncapture and machine learning algorithms,” Journal of Orthopaedics,\\\nvol. 49, pp. 140–147, 2024.\\\n12. [51]  \\\n13. [52]  \\\n14. [53]  \\\n15. [54]  \\\n16. [55]  \\\n17. [56]  \\\n18. [57]  \\\n19. [58]  \\\n20. [59]  \\\n21. [60]  \\\n22. [61]  \\\n\"]],\"start1\":5233,\"start2\":5233,\"length1\":8,\"length2\":5676}]"
metadata_diff: {"new":{},"deleted":[]}
encryption_cipher_text: 
encryption_applied: 0
updated_time: 2025-10-07T11:24:43.581Z
created_time: 2025-10-07T11:24:43.581Z
type_: 13